{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`make predictions` has to be run before any cell in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from booksuggest.evaluation.cb_evaluation import (\n",
    "    calculate_single_score, read_similar_books\n",
    ")\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(context='paper', font_scale=1.2, style='ticks', palette='muted',\n",
    "        rc={\"axes.labelsize\":16, \"ytick.labelsize\": 14, \"xtick.labelsize\":14,\n",
    "            \"font.family\": \"sans-serif\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to visualize the precision and recall scores against the amount of recommended books and find the optimal amount of books. Only the best perfoming content-based model will be considered -- the tag based model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_predictions_filepath = '../models/predictions/cb-results/tag-predictions.csv'\n",
    "test_cases = read_similar_books('../data/processed/similar_books.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_count_range = range(1, 10)\n",
    "scores = [calculate_single_score(tag_predictions_filepath, test_cases, rec_count)\n",
    "          for rec_count in rec_count_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_scores = [score['precision'] for score in scores]\n",
    "recall_scores = [score['recall'] for score in scores]\n",
    "df_scores = pd.DataFrame({\n",
    "    'precision': precision_scores,\n",
    "    'recall': recall_scores,\n",
    "    'book-number': list(rec_count_range)\n",
    "})\n",
    "df_scores = df_scores.set_index('book-number').stack().reset_index().rename(\n",
    "    columns={'level_1': 'Metric', 0: 'Metric value'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x='book-number', y='Metric value', hue='Metric',data=df_scores)\n",
    "ax.set_xlabel('Number of recommedations')\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.setp(ax.get_legend().get_texts(), fontsize='13') # for legend text\n",
    "plt.setp(ax.get_legend().get_title(), fontsize='13') # for legend title\n",
    "ax.get_figure().savefig('cb-tag-precision-recall-plot.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.get_figure().savefig('cb-tag-precision-recall-plot.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rs-venv",
   "language": "python",
   "name": "rs-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
